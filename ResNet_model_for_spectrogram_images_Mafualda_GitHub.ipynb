{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PKfC6vOH0ycw"
      },
      "source": [
        "# Import libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_3PdsUzBmV2f"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import shutil\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "%matplotlib inline\n",
        "import scipy.io # To use the '.mat' files\n",
        "import seaborn as sns\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import librosa\n",
        "import librosa.display\n",
        "from scipy.signal import butter, filtfilt\n",
        "import librosa\n",
        "import cv2\n",
        "from matplotlib.colors import Normalize\n",
        "from matplotlib import cm\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.optimizers import Adam"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Mount Google drive"
      ],
      "metadata": {
        "id": "l-YMLpTgFEfh"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wbOgTRMPnDn3",
        "outputId": "f0728e8b-d74e-4198-a167-ba1f96c91dc5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZYPHygvg0Hzz"
      },
      "source": [
        "#Prepare datasets for ResNet model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zjca2Ev9qAVW",
        "outputId": "ff1f7dfe-efc6-46c4-ed5a-ff2e8110d19b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 5511 images belonging to 4 classes.\n",
            "Found 1838 images belonging to 4 classes.\n"
          ]
        }
      ],
      "source": [
        "train_dir = '/content/drive/MyDrive/New_MF_data/New_Class/Reduced_Dataset_DNN/train'\n",
        "validation_dir = '/content/drive/MyDrive/New_MF_data/New_Class/Reduced_Dataset_DNN/validation'\n",
        "\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    rotation_range=40,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True,\n",
        "    fill_mode='nearest'\n",
        ")\n",
        "\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    train_dir,\n",
        "    target_size=(224, 224),\n",
        "    batch_size=128,\n",
        "    class_mode='categorical'\n",
        ")\n",
        "\n",
        "validation_generator = test_datagen.flow_from_directory(\n",
        "    validation_dir,\n",
        "    target_size=(224, 224),\n",
        "    batch_size=128,\n",
        "    class_mode='categorical'\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0P3ePUcJ0Pon"
      },
      "source": [
        "# Define ResNet model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7e3bjTbLsE8q"
      },
      "outputs": [],
      "source": [
        "# display, transform, read, split ...\n",
        "import numpy as np\n",
        "import cv2 as cv\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "# tensorflow\n",
        "import tensorflow.keras as keras\n",
        "import tensorflow as tf\n",
        "# image processing\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator, load_img\n",
        "# model / neural network\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.models import Sequential, Model\n",
        "from tensorflow.keras.applications import ResNet50\n",
        "from tensorflow.keras.applications.resnet50 import preprocess_input\n",
        "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Dropout\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from sklearn.model_selection import KFold\n",
        "from tensorflow.keras.applications import ResNet50\n",
        "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Dropout\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_ZJCpxBTy5MY"
      },
      "outputs": [],
      "source": [
        "def create_datagen():\n",
        "    train_datagen = ImageDataGenerator(\n",
        "        rescale=1./255,\n",
        "        rotation_range=40,\n",
        "        width_shift_range=0.2,\n",
        "        height_shift_range=0.2,\n",
        "        shear_range=0.2,\n",
        "        zoom_range=0.2,\n",
        "        horizontal_flip=True,\n",
        "        fill_mode='nearest',\n",
        "        preprocessing_function=tf.keras.applications.resnet50.preprocess_input)\n",
        "    return train_datagen\n",
        "\n",
        "def load_data(directory, img_height, img_width, batch_size):\n",
        "    datagen = create_datagen()\n",
        "    generator = datagen.flow_from_directory(\n",
        "        directory,\n",
        "        target_size=(img_height, img_width),\n",
        "        batch_size=batch_size,\n",
        "        class_mode='categorical',\n",
        "        shuffle=True)\n",
        "    return generator\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4sV2by5kshbn"
      },
      "outputs": [],
      "source": [
        "def build_model(num_classes):\n",
        "    base_model = ResNet50(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
        "    x = base_model.output\n",
        "    x = GlobalAveragePooling2D()(x)\n",
        "    x = Dense(1024, activation='relu')(x)\n",
        "    x = Dropout(0.5)(x)\n",
        "    predictions = Dense(num_classes, activation='softmax')(x)\n",
        "\n",
        "    # Freeze the layers of the base model\n",
        "    for layer in base_model.layers:\n",
        "        layer.trainable = False\n",
        "\n",
        "    model = Model(inputs=base_model.input, outputs=predictions)\n",
        "    model.compile(optimizer=Adam(lr=0.001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "    return model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vp8PZxbHxvia",
        "outputId": "aad70d95-69dd-443f-9005-26a90c383596"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "94765736/94765736 [==============================] - 4s 0us/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        }
      ],
      "source": [
        "model = build_model(4)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4Pnany1t0cnY"
      },
      "source": [
        "# Implement 5 cross-validation for train and evaluate ResNet model (Batch size epochs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H6uTHnfzsmrW"
      },
      "outputs": [],
      "source": [
        "def train_and_evaluate_model(directory, num_splits=5):\n",
        "    img_height, img_width = 224, 224\n",
        "    batch_size = 128\n",
        "    num_classes = 4\n",
        "    epochs=30\n",
        "\n",
        "    kf = KFold(n_splits=num_splits, shuffle=True, random_state=42)\n",
        "    fold_var = 1\n",
        "\n",
        "    results = []\n",
        "    for train_index, val_index in kf.split(np.zeros(3000), np.zeros(3000)):  # Adjust size based on your dataset\n",
        "        training_data = '/content/drive/MyDrive/New_MF_data/New_Class/Reduced_Dataset_DNN/train'  # Adjust path\n",
        "        validation_data = '/content/drive/MyDrive/New_MF_data/New_Class/Reduced_Dataset_DNN/validation'\n",
        "        train_generator = load_data(training_data, img_height, img_width, batch_size)\n",
        "        validation_generator = load_data(validation_data, img_height, img_width, batch_size)\n",
        "\n",
        "        model = build_model(num_classes)\n",
        "\n",
        "        # Fit data to model\n",
        "        history = model.fit(train_generator, steps_per_epoch=train_generator.samples // batch_size,\n",
        "                            validation_data=validation_generator,\n",
        "                            validation_steps=validation_generator.samples // batch_size,\n",
        "                            epochs=30, verbose=1)\n",
        "\n",
        "        results.append(history)\n",
        "\n",
        "        fold_var += 1\n",
        "\n",
        "    return model, results\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H0cdRW_P0pDg"
      },
      "source": [
        "# Run the training and validation datasets on ResNet model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tgkdmSZNswru",
        "outputId": "003785a5-91f1-4ae1-dbb2-ba6d68c30a0a"
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 5511 images belonging to 4 classes.\n",
            "Found 1838 images belonging to 4 classes.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "30/43 [===================>..........] - ETA: 13:27 - loss: 1.6002 - accuracy: 0.3315"
          ]
        }
      ],
      "source": [
        "directory = '/content/drive/MyDrive/New_MF_data/New_Class/Reduced_Dataset_DNN'\n",
        "model, results=train_and_evaluate_model(directory)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Save the model"
      ],
      "metadata": {
        "id": "-Fz3o1oEPuYp"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ooWhYYU76vqo"
      },
      "outputs": [],
      "source": [
        "# Assuming 'model' is your model instance\n",
        "model.save('/content/drive/MyDrive/New_MF_data/New_Class/my_model_5Hz_1000.h5')  # This will save in the TensorFlow SavedModel format by default"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load the saved model"
      ],
      "metadata": {
        "id": "L7uEMx6ZPzIy"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yvRY4Qsq7SUt"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.models import load_model\n",
        "\n",
        "# Load the model previously saved in HDF5 format\n",
        "model_h5 = load_model('/content/drive/MyDrive/New_MF_data/New_Class/my_model_5Hz_1000.h5')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training and validation accuracy and loss curves for all cross validation technique"
      ],
      "metadata": {
        "id": "psIeq95tP3sn"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SifLe5vzxt2E"
      },
      "outputs": [],
      "source": [
        "# Function to plot the history of all folds\n",
        "def plot_history(histories):\n",
        "    for i, history in enumerate(histories):\n",
        "        plt.figure(figsize=(14, 5))\n",
        "\n",
        "        # Plot accuracy\n",
        "        plt.subplot(1, 2, 1)\n",
        "        plt.plot(history.history['accuracy'], label='Train Accuracy')\n",
        "        plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
        "        plt.title(f'Fold {i+1} Accuracy')\n",
        "        plt.xlabel('Epoch')\n",
        "        plt.ylabel('Accuracy')\n",
        "        plt.legend()\n",
        "\n",
        "        # Plot loss\n",
        "        plt.subplot(1, 2, 2)\n",
        "        plt.plot(history.history['loss'], label='Train Loss')\n",
        "        plt.plot(history.history['val_loss'], label='Validation Loss')\n",
        "        plt.title(f'Fold {i+1} Loss')\n",
        "        plt.xlabel('Epoch')\n",
        "        plt.ylabel('Loss')\n",
        "        plt.legend()\n",
        "\n",
        "        plt.show()\n",
        "\n",
        "plot_history(results)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Confusion matrix, accuracy and prediction of the model"
      ],
      "metadata": {
        "id": "805pzGkBQDEF"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pdPlXP9y6vWS"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "import numpy as np\n",
        "import itertools\n",
        "def plot_confusion_matrix(cm, class_labels):\n",
        "    plt.figure(figsize=(10, 7))\n",
        "    plt.imshow(cm, interpolation='nearest', cmap=plt.cm.Blues)\n",
        "    plt.title('Confusion Matrix')\n",
        "    plt.colorbar()\n",
        "    tick_marks = np.arange(len(class_labels))\n",
        "    plt.xticks(tick_marks, class_labels, rotation=45)\n",
        "    plt.yticks(tick_marks, class_labels)\n",
        "\n",
        "    thresh = cm.max() / 2.\n",
        "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
        "        plt.text(j, i, format(cm[i, j], 'd'),\n",
        "                 horizontalalignment=\"center\",\n",
        "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.ylabel('True label')\n",
        "    plt.xlabel('Predicted label')\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-c0FVxg4Blel"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score\n",
        "\n",
        "# Setup the ImageDataGenerator\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "# Create a data generator for the test set\n",
        "test_generator = test_datagen.flow_from_directory(\n",
        "    '/content/drive/MyDrive/New_MF_data/New_Class/5HZ_Dataset_DNN/test',  # Path to test data\n",
        "    target_size=(224, 224),  # Assuming using 224x224 for ResNet input\n",
        "    batch_size=32,  # Batch size\n",
        "    class_mode='categorical',  # Type of problem\n",
        "    shuffle=False  # No need to shuffle for testing\n",
        ")\n",
        "\n",
        "# Modify the predict_and_evaluate function to use the correct variable names\n",
        "def predict_and_evaluate(model, generator):\n",
        "    generator.reset()\n",
        "    pred_indices = model.predict(generator, steps=generator.samples // generator.batch_size + 1)\n",
        "    predictions = np.argmax(pred_indices, axis=1)\n",
        "\n",
        "    true_classes = generator.classes\n",
        "    class_labels = list(generator.class_indices.keys())\n",
        "\n",
        "    cm = confusion_matrix(true_classes, predictions)\n",
        "    accuracy = accuracy_score(true_classes, predictions)  # Calculate the accuracy\n",
        "    return cm, class_labels, accuracy\n",
        "\n",
        "# Now, call the function with the correct generator\n",
        "conf_matrix, labels, test_accuracy = predict_and_evaluate(model, test_generator)\n",
        "print(\"Test Accuracy:\", test_accuracy*100)\n",
        "plot_confusion_matrix(conf_matrix, labels)\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}